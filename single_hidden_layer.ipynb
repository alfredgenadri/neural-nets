{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSingle hidden layer neural network\\n\\nA[1] = relu(W[1].T dot X + B[1])\\nA[2] = sigmoid(W[2].T dot A[1] + B[2])\\n\\nwhere X[1]: (n_x, n_examples), W[1]: (n_x, n_hidden), B[1]: (n_hidden, n_examples)\\nand A[1]: (n_hidden, n_examples), W[2]: (n_hidden, n_y), B[2]: (n_y, n_examples)\\n\\nConsidering the n_examples can vary from training to testing, the biases will be broadcasted\\n\\nFurther inquiries:\\nUnderstand relation between input topologies and network architecture\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Single hidden layer neural network\n",
    "\n",
    "A[1] = relu(W[1].T dot X + B[1])\n",
    "A[2] = sigmoid(W[2].T dot A[1] + B[2])\n",
    "\n",
    "where X[1]: (n_x, n_examples), W[1]: (n_x, n_hidden), B[1]: (n_hidden, n_examples)\n",
    "and A[1]: (n_hidden, n_examples), W[2]: (n_hidden, n_y), B[2]: (n_y, n_examples)\n",
    "\n",
    "Considering the n_examples can vary from training to testing, the biases will be broadcasted\n",
    "\n",
    "Further inquiries:\n",
    "Understand relation between input topologies and network architecture\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input dimensions: (12288, 209)\n",
      "Testing input dimensions: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    # load training and test data: pixel values for cat images and binary classification output\n",
    "\n",
    "    with h5py.File('datasets/train_catvnoncat.h5', \"r\") as train_dataset:\n",
    "        train_x_original = np.array(train_dataset[\"train_set_x\"][:])\n",
    "        train_y_original = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "    with h5py.File('datasets/test_catvnoncat.h5', \"r\") as test_dataset:\n",
    "        test_x_original = np.array(test_dataset[\"test_set_x\"][:])\n",
    "        test_y_original = np.array(test_dataset[\"test_set_y\"][:])\n",
    "        classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "\n",
    "    # output matrix of the form (1, n) where each column is a boolean \n",
    "    train_y_original = train_y_original.reshape((1, train_y_original.shape[0]))\n",
    "    test_y_original = test_y_original.reshape((1, test_y_original.shape[0]))\n",
    "\n",
    "    return train_x_original, train_y_original, test_x_original, test_y_original, classes\n",
    "\n",
    "train_x_original, train_y_original, test_x_original, test_y_original, classes = load_dataset()\n",
    "\n",
    "n_train = train_x_original.shape[0] # number of training examples\n",
    "n_test = test_x_original.shape[0] # number of test examples\n",
    "num_pixels = train_x_original.shape[1] # number of pixels = height = width\n",
    "img_shape = (num_pixels, num_pixels, train_x_original.shape[3]) # height, width, 3 channels (RGB)\n",
    "\n",
    "# flatten data and standardize pixel values\n",
    "# rows represent pixels and columns different training examples\n",
    "\n",
    "train_x_flatten = train_x_original.reshape(n_train, -1).T\n",
    "test_x_flatten = test_x_original.reshape(n_test, -1).T\n",
    "\n",
    "print('Training input dimensions: ' + str(train_x_flatten.shape))\n",
    "print('Testing input dimensions: ' + str(test_x_flatten.shape))\n",
    "\n",
    "# distribute the data over the range 0-1\n",
    "train_x = train_x_flatten / 255\n",
    "test_x = test_x_flatten / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 12288\n",
    "n_hidden = 4\n",
    "n_y = 1\n",
    "layer_sizes = [n_x, n_hidden, n_y]\n",
    "n_layers = len(layer_sizes) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_params(layer_sizes):\n",
    "    params = dict()\n",
    "    for l in range(1, len(layer_sizes)):\n",
    "        params['W{layer}'.format(layer=l)] = np.random.randn(layer_sizes[l - 1],layer_sizes[l]) * np.sqrt(2/layer_sizes[l-1]) # He et al. initialization\n",
    "        params['b{layer}'.format(layer=l)] = np.zeros((layer_sizes[l], 1))\n",
    "    return params\n",
    "\n",
    "def forward_prop(params, X):\n",
    "    cache = dict()\n",
    "    cache['A0'] = X\n",
    "    for l in range(1, n_layers + 1):\n",
    "        Z_l = np.dot(params['W{layer}'.format(layer=l)].T, cache['A{prev_l}'.format(prev_l=l-1)]) + params['b{layer}'.format(layer=l)]\n",
    "        cache['A{layer}'.format(layer=l)] = tanh(Z_l) if l != n_layers else sigmoid(Z_l)\n",
    "    return params, cache\n",
    "\n",
    "def compute_cost(Ak, Y):\n",
    "    cost = -np.sum(np.multiply(np.log(Ak), Y) + np.multiply((1 - Y), np.log(1 - Ak))) / Y.shape[1]\n",
    "    return np.squeeze(cost)\n",
    "\n",
    "def backward_prop(params, cache, X, Y):\n",
    "\n",
    "    n = X.shape[1]\n",
    "    dZ2 = Y - cache['A2']\n",
    "    dW2 = (-1/n) * np.dot(dZ2, cache['A1'].T)\n",
    "    db2 = (-1/n) * np.sum(dZ2, axis=1, keepdims=1)\n",
    "    dZ1 = np.multiply(np.dot(params['W2'].T, dZ2), 1 - np.power(cache['A1'], 2))\n",
    "    dW1 = (-1/n) * np.dot(dZ1, cache['A0'].T)\n",
    "    db1 = (-1/n) * np.sum(dZ1, axis=1, keepdims=1)\n",
    "    \n",
    "    return {'dW2': dW2,\n",
    "            'db2': db2,\n",
    "            'dW1': dW1,\n",
    "            'db1': db1 }\n",
    "\n",
    "def optimize(params, grads, learning_rate):\n",
    "    for param, val in params.items():\n",
    "        params[param] -= learning_rate * grads['d' + param]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.00326185  0.0111998   0.00158111  0.00868104]\n",
      " [ 0.01414519  0.01397113 -0.02165932 -0.01543981]\n",
      " [ 0.02089953  0.00764427  0.00861871  0.01288176]\n",
      " ...\n",
      " [-0.01498252  0.00119515  0.00295725  0.00606371]\n",
      " [-0.00745684  0.01134148 -0.00652726  0.02587092]\n",
      " [-0.01536979 -0.02027315  0.01602498  0.01084437]]\n",
      "B1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.35132324]\n",
      " [-0.60740874]\n",
      " [ 0.44115692]\n",
      " [-1.11506244]]\n",
      "B2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "# Method output validation\n",
    "\n",
    "parameters = init_params(layer_sizes=layer_sizes)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"B1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"B2 = \" + str(parameters[\"b2\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(params, X):\n",
    "    n = X.shape[1]\n",
    "    _, cache = forward_prop(params, X)\n",
    "    Y_pred = np.zeros((1, n))\n",
    "    \n",
    "    for idx in range(n):\n",
    "        Y_pred[0, idx] = 1 if cache['A{0}'.format(n_layers)][0, idx] > 0.5 else 0 # thresholding\n",
    "    return Y_pred\n",
    "    \n",
    "def model(epoch_num, learning_rate, X, Y):\n",
    "    \n",
    "    params = init_params(layer_sizes)\n",
    "    for epoch in range(epoch_num):\n",
    "        params, cache = forward_prop(params, X)\n",
    "        cost = compute_cost(cache['A2'], Y)\n",
    "        grads = backward_prop(params, cache, X, Y)\n",
    "        params = optimize(params, grads, learning_rate)\n",
    "        if (epoch % 1000 == 0):\n",
    "            print('Cost after iteration {iteration}: '.format(iteration=epoch))\n",
    "    return params\n",
    "\n",
    "m = model(5000, 0.005, train_x, train_y_original)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
